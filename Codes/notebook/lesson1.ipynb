{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chương I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing LÀ GÌ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP - hay Xử lý ngôn ngữ tự nhiên - là viết tắt của một loạt các kỹ thuật được thiết kế để giúp máy học từ văn bản. Xử lý ngôn ngữ tự nhiên hỗ trợ mọi thứ từ chatbot đến công cụ tìm kiếm và được sử dụng trong nhiều tác vụ khác nhau như phân tích tình cảm và dịch máy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Thư viện cơ bản cần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ Truy suất xem file data(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Nhom15DHIOT17A/Codes/data\\sample_submission.csv\n",
      "D:/Nhom15DHIOT17A/Codes/data\\test.csv\n",
      "D:/Nhom15DHIOT17A/Codes/data\\test_predictions.csv\n",
      "D:/Nhom15DHIOT17A/Codes/data\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('D:/Nhom15DHIOT17A/Codes/data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Đọc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"D:/Nhom15DHIOT17A/Codes/data/train.csv\")\n",
    "test_df = pd.read_csv(\"D:/Nhom15DHIOT17A/Codes/data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/ Phân loại cơ bản đâu là thảm họa và đâu không phải là thảm họa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Không phải thảm họa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thảm họa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n",
       "       'Forest fire near La Ronge Sask. Canada',\n",
       "       \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\",\n",
       "       ...,\n",
       "       'M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ',\n",
       "       'Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.',\n",
       "       'The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"]==1][\"text\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trong bộ dữ liệu này , cột target dùng để phân loại tweet\n",
    "   #### 1.target = 0: Tweet không liên quan đến thảm họa, thường chỉ đề cập đến các hoạt động hoặc cảm xúc bình thường, không mang tính chất nguy hiểm. Ví dụ: \"What's up man?\", \"I love fruits\".\n",
    "\n",
    "   #### 2.target = 1: Tweet liên quan đến thảm họa, thường mô tả sự cố hoặc thiên tai thực sự có thể gây nguy hiểm. Ví dụ: \"Forest fire near La Ronge Sask. Canada\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5/ Xây dựng vecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sau khi phân loại được đâu là tweet thảm họa đâu là tweet không phải thảm họa.Nhóm sử dụng scikit-learn CountVectorizer để đếm xem số lượng từ trong mỗi tweet và chuyển thành dữ liệu máy học."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Với 5 tweet đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nội dung của 5 tweet đầu tiên:\n",
      "['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'\n",
      " 'Forest fire near La Ronge Sask. Canada'\n",
      " \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\"\n",
      " '13,000 people receive #wildfires evacuation orders in California '\n",
      " 'Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ']\n",
      "\n",
      "Danh sách tất cả các từ đã được trích xuất:\n",
      "['000' '13' 'alaska' 'all' 'allah' 'are' 'as' 'asked' 'being' 'by'\n",
      " 'california' 'canada' 'deeds' 'earthquake' 'evacuation' 'expected' 'fire'\n",
      " 'forest' 'forgive' 'from' 'got' 'in' 'into' 'just' 'la' 'may' 'near' 'no'\n",
      " 'notified' 'of' 'officers' 'or' 'orders' 'other' 'our' 'people' 'photo'\n",
      " 'place' 'pours' 'reason' 'receive' 'residents' 'ronge' 'ruby' 'sask'\n",
      " 'school' 'sent' 'shelter' 'smoke' 'the' 'this' 'to' 'us' 'wildfires']\n",
      "\n",
      "Từ vựng và chỉ số tương ứng:\n",
      "{'our': 34, 'deeds': 12, 'are': 5, 'the': 49, 'reason': 39, 'of': 29, 'this': 50, 'earthquake': 13, 'may': 25, 'allah': 4, 'forgive': 18, 'us': 52, 'all': 3, 'forest': 17, 'fire': 16, 'near': 26, 'la': 24, 'ronge': 42, 'sask': 44, 'canada': 11, 'residents': 41, 'asked': 7, 'to': 51, 'shelter': 47, 'in': 21, 'place': 37, 'being': 8, 'notified': 28, 'by': 9, 'officers': 30, 'no': 27, 'other': 33, 'evacuation': 14, 'or': 31, 'orders': 32, 'expected': 15, '13': 1, '000': 0, 'people': 35, 'receive': 40, 'wildfires': 53, 'california': 10, 'just': 23, 'got': 20, 'sent': 46, 'photo': 36, 'from': 19, 'ruby': 43, 'alaska': 2, 'as': 6, 'smoke': 48, 'pours': 38, 'into': 22, 'school': 45}\n",
      "\n",
      "Ma trận vector chi tiết của 5 tweet đầu tiên:\n",
      "(0, 34)\t1\n",
      "(0, 12)\t1\n",
      "(0, 5)\t1\n",
      "(0, 49)\t1\n",
      "(0, 39)\t1\n",
      "(0, 29)\t1\n",
      "(0, 50)\t1\n",
      "(0, 13)\t1\n",
      "(0, 25)\t1\n",
      "(0, 4)\t1\n",
      "(0, 18)\t1\n",
      "(0, 52)\t1\n",
      "(0, 3)\t1\n",
      "(1, 17)\t1\n",
      "(1, 16)\t1\n",
      "(1, 26)\t1\n",
      "(1, 24)\t1\n",
      "(1, 42)\t1\n",
      "(1, 44)\t1\n",
      "(1, 11)\t1\n",
      "(2, 5)\t2\n",
      "(2, 3)\t1\n",
      "(2, 41)\t1\n",
      "(2, 7)\t1\n",
      "(2, 51)\t1\n",
      "(2, 47)\t2\n",
      "(2, 21)\t2\n",
      "(2, 37)\t2\n",
      "(2, 8)\t1\n",
      "(2, 28)\t1\n",
      "(2, 9)\t1\n",
      "(2, 30)\t1\n",
      "(2, 27)\t1\n",
      "(2, 33)\t1\n",
      "(2, 14)\t1\n",
      "(2, 31)\t1\n",
      "(2, 32)\t1\n",
      "(2, 15)\t1\n",
      "(3, 21)\t1\n",
      "(3, 14)\t1\n",
      "(3, 32)\t1\n",
      "(3, 1)\t1\n",
      "(3, 0)\t1\n",
      "(3, 35)\t1\n",
      "(3, 40)\t1\n",
      "(3, 53)\t1\n",
      "(3, 10)\t1\n",
      "(4, 50)\t1\n",
      "(4, 53)\t1\n",
      "(4, 23)\t1\n",
      "(4, 20)\t1\n",
      "(4, 46)\t1\n",
      "(4, 36)\t1\n",
      "(4, 19)\t2\n",
      "(4, 43)\t1\n",
      "(4, 2)\t1\n",
      "(4, 6)\t1\n",
      "(4, 48)\t1\n",
      "(4, 38)\t1\n",
      "(4, 22)\t1\n",
      "(4, 45)\t1\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo CountVectorizer\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "# Đếm số từ trong 5 tweet đầu tiên trong dữ liệu\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])\n",
    "\n",
    "# In nội dung của 5 tweet đầu tiên\n",
    "print(\"Nội dung của 5 tweet đầu tiên:\")\n",
    "print(train_df[\"text\"][0:5].values)\n",
    "\n",
    "# In danh sách tất cả các từ đã được trích xuất từ các tweet đầu tiên (từ vựng)\n",
    "print(\"\\nDanh sách tất cả các từ đã được trích xuất:\")\n",
    "print(count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# In từ vựng và chỉ số tương ứng\n",
    "print(\"\\nTừ vựng và chỉ số tương ứng:\")\n",
    "print(count_vectorizer.vocabulary_)\n",
    "\n",
    "# In ma trận vector chi tiết của 5 tweet đầu tiên\n",
    "print(\"\\nMa trận vector chi tiết của 5 tweet đầu tiên:\")\n",
    "rows, cols = example_train_vectors.nonzero()  # Lấy chỉ số hàng và cột của ma trận không rỗng\n",
    "for r, c in zip(rows, cols):\n",
    "    print(f\"({r}, {c})\\t{example_train_vectors[r, c]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54)\n",
      "[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dòng sau đây sẽ in ra kích thước của vector đầu tiên\n",
    "print(example_train_vectors[0].todense().shape)\n",
    "# Dòng sau đây sẽ in ra toàn bộ giá trị của vector đầu tiên dưới dạng ma trận dày đặc\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải thích ý nghĩa về 5 tweet đầu tiên\n",
    "##### 1.Có 54 từ trong 5 tweet đầu tiên\n",
    "##### 2.Tweet đầu tiên chỉ chứa một số mã thông báo duy nhất đó - tất cả các số khác không ở trên là các mã thông báo TỒN TẠI trong tweet đầu tiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6/Thực hiện kiểm tra chéo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục tiêu của việc kiểm tra chéo\n",
    "##### 1.kiểm tra mô hình và đánh giá hiệu suất trên dữ liệu huấn luyện\n",
    "##### 2.Phương pháp sử dụng cross-validation chia dữ liệu thành nhiều phần huấn luyện mô hình trên một phần và kiểm tra các phần còn lại và lặp lại quá trình nhiều lần\n",
    "##### 3.Sử dụng F1 score làm chỉ số đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Điểm F1 cho từng lần kiểm tra chéo: [0.59453669 0.5642787  0.64082434]\n",
      "Điểm F1 trung bình: 0.5998799106916805\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Khởi tạo CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Chia dữ liệu thành các vector đặc trưng\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "# Chuyển đổi dữ liệu kiểm tra mà không sử dụng .fit_transform()\n",
    "# Đảm bảo rằng các token trong train_vectors là duy nhất\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# Khởi tạo mô hình phân loại Ridge\n",
    "clf = linear_model.RidgeClassifier()\n",
    "\n",
    "# Thực hiện kiểm tra chéo để đánh giá mô hình\n",
    "scores = model_selection.cross_val_score(\n",
    "    clf,  # Mô hình phân loại đã được định nghĩa\n",
    "    train_vectors,  # Ma trận vector đặc trưng của dữ liệu huấn luyện\n",
    "    train_df[\"target\"],  # Nhãn mục tiêu cho dữ liệu huấn luyện\n",
    "    cv=3,  # Số lượng phần (folds) để chia dữ liệu (3 phần ở đây)\n",
    "    scoring=\"f1\"  # Sử dụng F1 score làm chỉ số đánh giá\n",
    ")\n",
    "\n",
    "# In ra các điểm F1 cho từng lần kiểm tra chéo\n",
    "print(\"Điểm F1 cho từng lần kiểm tra chéo:\", scores)\n",
    "\n",
    "# Tính và in ra điểm F1 trung bình\n",
    "print(\"Điểm F1 trung bình:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vectors, train_df[\"target\"])\n",
    "sample_submission = pd.read_csv(\"D:/Nhom15DHIOT17A/Codes/data/sample_submission.csv\")\n",
    "sample_submission[\"target\"] = clf.predict(test_vectors)\n",
    "sample_submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
